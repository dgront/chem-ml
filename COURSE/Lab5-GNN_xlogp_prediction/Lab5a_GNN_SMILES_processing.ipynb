{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d2ac0d6"
      },
      "source": [
        "### Download training data from the web\n",
        "\n",
        "Download a CSV file containing molecular data for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzGhyWGecIw4",
        "outputId": "53056396-967e-4007-c80d-72cd621f8619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['cmpdname', 'mf', 'isosmiles', 'xlogp'], ['1-Aminopropan-2-ol', 'C3H9NO', 'CC(CN)O', '-1'], ['\"1-Chloro-2,4-dinitrobenzene\"', 'C6H3ClN2O4', 'C1=CC(=C(C=C1[N+](=O)[O-])[N+](=O)[O-])Cl', '2.3'], ['9-Ethyladenine', 'C7H9N5', 'CCN1C=NC2=C(N=CN=C21)N', '0.2'], ['\"1,2-Dichloroethane\"', 'C2H4Cl2', 'C(CCl)Cl', '1.5']]\n",
            "266712\n"
          ]
        }
      ],
      "source": [
        "import base64\n",
        "import requests\n",
        "\n",
        "input_data=\"https://raw.githubusercontent.com/dgront/chem-ml/refs/heads/main/INPUTS/xlogp_JChemEdu/xlogp.tsv\"\n",
        "req = requests.get(input_data)\n",
        "table = []\n",
        "for row in req.text.splitlines():\n",
        "  tokens = row.split(\"\\t\")\n",
        "  if len(tokens) == 4:\n",
        "    if len(tokens[2]) == 0: continue\n",
        "    table.append(tokens)\n",
        "\n",
        "print(table[0:5])\n",
        "print(len(table))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "850a83a2"
      },
      "source": [
        "### Install dependencies\n",
        "\n",
        "We need RDKit to process SMILES; tensorflow to prepare training data as tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2CXdRsSiIbi",
        "outputId": "6e57efa5-f598-45e7-840d-f7aa30c31808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.11/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (11.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip3.11 install numpy rdkit-pypi\n",
        "from rdkit import Chem\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe4f67be"
      },
      "source": [
        "### Extract features from SMILES\n",
        "\n",
        "First we define a function that accepts a SMILES and returns data we need to train GNN model. For a molecule of N atoms and M bonds, the function returns:\n",
        "\n",
        "*   list of element names for all atoms - N strings like \"C\", \"Fe\", etc\n",
        "*   list of hybridisation for all atoms - N strings like \"sp2\", \"sp\" etc\n",
        "*   list of bond types for all bonds - M tuples (int, int, str) for a bond that connects atoms given by the two indexes; the string may be \"SINGLE\", \"DOUBLE\" etc to denote the bond type\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "p87mMJcygktu"
      },
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "def extract_atoms_and_bonds(smiles: str) -> Tuple[List[str], List[str], List[Tuple[int, int, str]]]:\n",
        "    # Parse SMILES to molecule\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        raise ValueError(\"Invalid SMILES string.\")\n",
        "\n",
        "    mol = Chem.AddHs(mol)\n",
        "\n",
        "    # Extract atom list\n",
        "    atom_list = []\n",
        "    hybrid_list = []\n",
        "    for atom in mol.GetAtoms():\n",
        "        atom_symbol = atom.GetSymbol()\n",
        "        atom_list.append(atom_symbol)\n",
        "        atom_hybridization = atom.GetHybridization()\n",
        "        hybrid_list.append(str(atom_hybridization))\n",
        "\n",
        "    # Extract bond list\n",
        "    bond_list = []\n",
        "    for bond in mol.GetBonds():\n",
        "        begin_idx = bond.GetBeginAtomIdx()\n",
        "        end_idx = bond.GetEndAtomIdx()\n",
        "        bond_type = bond.GetBondType()  # e.g., SINGLE, DOUBLE, etc.\n",
        "        bond_list.append((begin_idx, end_idx, str(bond_type)))\n",
        "\n",
        "    return atom_list, hybrid_list, bond_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c0f66f9"
      },
      "source": [
        "**Define a list of elements and bond types that will be explicitely encoded** in one-hot manner. Here we list only most popular elements. Every element that is not on the list, will be encoded as *unknown*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Lnndrqd-uaqe"
      },
      "outputs": [],
      "source": [
        "allowed_bond_types = ['SINGLE', 'DOUBLE', 'TRIPLE', 'AROMATIC']\n",
        "allowed_elements = ['C', 'N', 'O', 'H', 'Cl', 'P', 'S', 'As', 'Br', 'Ca', 'Se', 'I', 'K', 'Mg', 'Na', 'Ni', 'W', 'F', 'B', 'Hg', 'Al',  'Li', 'Zn', 'Si',  'Co', 'Pb', 'Sn',  'Cu',  'Ba', 'Fe', 'Mn', 'Cr']\n",
        "allowed_hybridization = ['SP', 'SP2', 'SP3', 'SP3D', 'SP3D2', 'S', 'UNSPECIFIED']\n",
        "\n",
        "allowed_bond_indexed = {token: idx for idx, token in enumerate(allowed_bond_types)}\n",
        "allowed_elements_indexed = {token: idx for idx, token in enumerate(allowed_elements)}\n",
        "allowed_hybridization_indexed = {token: idx for idx, token in enumerate(allowed_hybridization)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a37e7cc8"
      },
      "source": [
        "A function that provides **one-hot encoding of a string** by finding its position on a list of K allowed strings. If not found, the given `input_string` is encoded as K+1st variant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "g5K9ZrkvwBNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ee5fea-504d-4423-9484-dd001a08abb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(33,), dtype=int64)\n",
            "tf.Tensor([1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(33,), dtype=int64)\n",
            "tf.Tensor([0 1 0 0 0], shape=(5,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def one_hot_encode(allowed_tokens, input_string):\n",
        "    \"\"\"\n",
        "    One-hot encode a string based on a given dict of string tokens.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A 1D numpy array representing the one-hot encoded token.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize an empty matrix\n",
        "    one_hot_matrix = np.zeros((len(allowed_tokens) + 1), dtype=int)\n",
        "\n",
        "    # Fill in the one-hot matrix\n",
        "    if input_string in allowed_tokens:\n",
        "        one_hot_matrix[allowed_tokens[input_string]] = 1\n",
        "    else:\n",
        "        one_hot_matrix[len(allowed_tokens)] = 1\n",
        "\n",
        "    return one_hot_matrix\n",
        "\n",
        "# ---- a short test\n",
        "print(tf.convert_to_tensor(one_hot_encode(allowed_elements_indexed, \"Cl\")))\n",
        "print(tf.convert_to_tensor(one_hot_encode(allowed_elements_indexed, \"C\")))\n",
        "print(tf.convert_to_tensor(one_hot_encode(allowed_bond_indexed, \"DOUBLE\")))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4029238"
      },
      "source": [
        "Load the SMILES dataset; use the extract_atoms_and_bonds() function to extract bonds and atoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1Te2RwaxwvS1",
        "outputId": "7670094d-cfc7-4af7-c4d4-d73b1328a683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[17:03:42] WARNING: not removing hydrogen atom without neighbors\n",
            "[17:03:42] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n",
            "can't parse log(p): NULL\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "V_features = []       # features for atoms = element one-hot + hybridisation one-hot\n",
        "E_indexing = []       # bond indexes as (in, int) tuples\n",
        "E_features = []       # bond features: bond type one-hot\n",
        "Y_labels   = []       # log(p) - the value we predict\n",
        "names      = []       # names of the compounds (just in case)\n",
        "formulas   = []       # formular of the compounds (just in case)\n",
        "\n",
        "# iterate over all the smiles\n",
        "for name, formula, smiles, logp in table[1:1000]:\n",
        "    # get atoms and bonds data for that SMILES\n",
        "    try:\n",
        "      atoms, hybridization, bonds = extract_atoms_and_bonds(smiles)\n",
        "      if len(atoms) < 3 or len(bonds) < 2: continue   # skip if the compound is too small\n",
        "    except:\n",
        "      print(\"Problematic SMILES:\",smiles)\n",
        "    try:\n",
        "      logp_flt = float(logp)\n",
        "    except:\n",
        "      print(\"can't parse log(p):\",logp)\n",
        "\n",
        "    encoded_elements = tf.stack([one_hot_encode(allowed_elements_indexed, a) for a in atoms])\n",
        "    encoded_hybrid = tf.stack([one_hot_encode(allowed_hybridization_indexed, h) for h in hybridization])\n",
        "    encoded_atoms = tf.concat([encoded_elements, encoded_hybrid], axis=1)\n",
        "\n",
        "    indexing = tf.convert_to_tensor([(bi, bj) for (bi, bj, _t) in bonds])\n",
        "    indexing = tf.transpose(indexing)\n",
        "\n",
        "    encoded_bonds = tf.stack([one_hot_encode(allowed_bond_indexed, b[2]) for b in bonds])\n",
        "    V_features.append(encoded_atoms)\n",
        "    E_indexing.append(indexing)\n",
        "    E_features.append(encoded_bonds)\n",
        "    logp_flt = tf.convert_to_tensor([logp_flt], dtype=tf.float32)\n",
        "\n",
        "    Y_labels.append(logp_flt)\n",
        "    names.append(name)\n",
        "    formulas.append(formula)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- a short test\n",
        "print(formulas[10])\n",
        "print(V_features[10])\n",
        "print(E_features[10])\n",
        "print(E_indexing[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J487i5IgWsl",
        "outputId": "6b16d62e-4ada-4f93-af5f-7fb43b9857ad"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C2H3ClO\n",
            "tf.Tensor(\n",
            "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            "  0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            "  0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 1 0]], shape=(7, 41), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 0 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]], shape=(6, 5), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0 1 0 0 0 1]\n",
            " [1 2 3 4 5 6]], shape=(2, 6), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0be8f606"
      },
      "source": [
        "**Preapre training / validation / test data sets**\n",
        "\n",
        "All the molecules are split in 60%, 20%, 20% ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "qNNtmnTVN6Z8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Define the split ratios\n",
        "train_ratio = 0.6\n",
        "val_ratio = 0.2\n",
        "test_ratio = 0.2\n",
        "\n",
        "# Calculate the split indices\n",
        "data_len = len(V_features)\n",
        "train_split = int(train_ratio * data_len)\n",
        "val_split = int((train_ratio + val_ratio) * data_len)\n",
        "\n",
        "# Generate shuffled indices\n",
        "indices = list(range(data_len))\n",
        "random.shuffle(indices)\n",
        "\n",
        "# Split the lists using the shuffled indices\n",
        "V_train = [V_features[i] for i in indices[:train_split]]\n",
        "V_val = [V_features[i] for i in indices[train_split:val_split]]\n",
        "V_test = [V_features[i] for i in indices[val_split:]]\n",
        "\n",
        "E_i_train = [E_indexing[i] for i in indices[:train_split]]\n",
        "E_i_val = [E_indexing[i] for i in indices[train_split:val_split]]\n",
        "E_i_test = [E_indexing[i] for i in indices[val_split:]]\n",
        "\n",
        "E_f_train = [E_features[i] for i in indices[:train_split]]\n",
        "E_f_val = [E_features[i] for i in indices[train_split:val_split]]\n",
        "E_f_test = [E_features[i] for i in indices[val_split:]]\n",
        "\n",
        "Y_train = [Y_labels[i] for i in indices[:train_split]]\n",
        "Y_val = [Y_labels[i] for i in indices[train_split:val_split]]\n",
        "Y_test = [Y_labels[i] for i in indices[val_split:]]\n",
        "\n",
        "names_train = [names[i] for i in indices[:train_split]]\n",
        "names_val = [names[i] for i in indices[train_split:val_split]]\n",
        "names_test = [names[i] for i in indices[val_split:]]\n",
        "\n",
        "formulas_train = [formulas[i] for i in indices[:train_split]]\n",
        "formulas_val = [formulas[i] for i in indices[train_split:val_split]]\n",
        "formulas_test = [formulas[i] for i in indices[val_split:]]\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}