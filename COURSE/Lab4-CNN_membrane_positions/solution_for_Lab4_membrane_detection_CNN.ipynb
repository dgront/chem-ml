{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Read and parse the training data"
      ],
      "metadata": {
        "id": "SpQH3Un4YYoE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbPd8Ca1Xmuz",
        "outputId": "53a1b27d-414a-4c8c-cfd0-34e03f44e94e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  pdb_id chain_code                                           sequence  \\\n",
            "0   1a0b          _  TTEENSKSEALLDIPMLEQYLELVGPKLITDGLAVFEKMMPGYVSV...   \n",
            "1   2a00          A  MGHHHHHHHHHHSSGHGGRHNRQASEFIPAQGVDEKTLADAAQLAS...   \n",
            "2   7a0w          A  MKHLHRFFSSDASGGIILIIAAALAMLMANMGATSGWYHDFLETPV...   \n",
            "3   7a0w          B  MKHLHRFFSSDASGGIILIIAAALAMLMANMGATSGWYHDFLETPV...   \n",
            "4   2a06          A  TATYAQALQSVPETQVSQLDNGLRVASEQSSQPTCTVGVWIDAGSR...   \n",
            "\n",
            "                                        region_types  \n",
            "0  UUUUUU1111111111111111111111111111111111111111...  \n",
            "1  UUUUUUUUUUUUUUUUUUUU11111111111111111111111111...  \n",
            "2  UUUUUUUUUUU111HHHHHHHHHHHHHH222222222222222222...  \n",
            "3  UUUUUUUUUU1111HHHHHHHHHHHHHH222222222222222222...  \n",
            "4  2222222222222222222222222222222222222222222222...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace with your actual GitHub repo URL\n",
        "url = \"https://raw.githubusercontent.com/dgront/chem-ml/refs/heads/main/INPUTS/membrane_proteins/pdbtm.dat\"\n",
        "\n",
        "try:\n",
        "  df = pd.read_csv(url, sep='\\t')\n",
        "  print(df.head())  # Display the first few rows of the DataFrame\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = df['sequence'].tolist()\n",
        "region_types = df['region_types'].tolist()\n",
        "print(len(sequences), len(region_types))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBvfrBocYTDU",
        "outputId": "c9c48b83-ffc1-429b-af09-019725e69d78"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65705 65705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Encode both inputs and outputs in one-hot encoding"
      ],
      "metadata": {
        "id": "jNu6YSPyY5CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def one_hot_encode(char_list, input_string):\n",
        "    \"\"\"\n",
        "    One-hot encode a string based on a given list of characters.\n",
        "\n",
        "    Parameters:\n",
        "        char_list (list or str): List of unique characters defining the encoding space.\n",
        "        input_string (str): The string to encode.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A 2D numpy array representing the one-hot encoded string.\n",
        "    \"\"\"\n",
        "    # Create a mapping from character to index\n",
        "    char_to_index = {char: idx for idx, char in enumerate(char_list)}\n",
        "    num_chars = len(char_list)\n",
        "\n",
        "    # Initialize an empty matrix\n",
        "    one_hot_matrix = np.zeros((len(input_string), num_chars), dtype=int)\n",
        "\n",
        "    # Fill in the one-hot matrix\n",
        "    for i, char in enumerate(input_string):\n",
        "        if char in char_to_index:\n",
        "            one_hot_matrix[i, char_to_index[char]] = 1\n",
        "        else:\n",
        "            raise ValueError(f\"Character '{char}' not found in the provided character list.\")\n",
        "\n",
        "    return one_hot_matrix"
      ],
      "metadata": {
        "id": "6TKJwJK8Y_AB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aa_letters = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
        "tm_letters = list(\"12HUL.FIB\")"
      ],
      "metadata": {
        "id": "upPgxEszZmll"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r0 = one_hot_encode(tm_letters, region_types[0])"
      ],
      "metadata": {
        "id": "nJ2cHuKOZx6n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution with padded tensors"
      ],
      "metadata": {
        "id": "h3TnRr08fD7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%script false --no-raise-error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "N = len(region_types)\n",
        "N = 1000\n",
        "labels = []\n",
        "for i in range(N):\n",
        "  labels.append(one_hot_encode(tm_letters, region_types[i]))\n",
        "\n",
        "padded_labels = pad_sequences(labels, padding='post', dtype='float32')\n",
        "\n",
        "padded_labels = tf.constant(padded_labels)\n",
        "padded_labels.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4WG3-X2aG8Q",
        "outputId": "893b37c2-4b9d-487a-8500-c5aec799b172"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1000, 1596, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution with separate tensors"
      ],
      "metadata": {
        "id": "HSKzP4UYfJyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#N = len(region_types)\n",
        "N = 10000\n",
        "labels = []\n",
        "features = []\n",
        "for i in range(N):\n",
        "  try:\n",
        "    li = one_hot_encode(tm_letters, region_types[i])\n",
        "    fi = one_hot_encode(aa_letters, sequences[i])\n",
        "    labels.append(li)\n",
        "    features.append(fi)\n",
        "  except:\n",
        "    # print(i, sequences[i])\n",
        "    pass\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fsglGokufNEN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(features),len(features[0]),len(labels),len(labels[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhuQtAKjbrr5",
        "outputId": "199e3a87-2b51-4d37-8cb4-caf76b480858"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9628 125 9628 125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# split data into two sets: training and validation\n",
        "\n",
        "features_train, features_val, labels_train, labels_val = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
        "print([len(lista) for lista in [features_train, features_val, labels_train, labels_val ]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRdFsDYCD2yE",
        "outputId": "f817e881-8d49-4d07-c838-463100fb4202"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6739, 2889, 6739, 2889]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_dataset(features_list, labels_list):\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        lambda: zip(features_list, labels_list),\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(None, 20), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(None, 9), dtype=tf.float32)\n",
        "        )\n",
        "    ).batch(1)\n",
        "\n",
        "training_dataset = create_dataset(features_train, labels_train)\n",
        "validation_dataset = create_dataset(features_val, labels_val)"
      ],
      "metadata": {
        "id": "QNTJ1tYbjBoq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: describe shape of training_dataset and validation_dataset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Assuming features_train, labels_train, features_val, and labels_val are defined as in the provided code\n",
        "\n",
        "# Inspect the shapes of elements in the datasets\n",
        "for ft, lb in training_dataset.take(1):  # Take one batch from the training dataset\n",
        "    print(\"Training Dataset:\")\n",
        "    print(\"Features shape:\", np.array(ft).shape)\n",
        "    print(\"Labels shape:\", np.array(lb).shape)\n",
        "\n",
        "for ft, lb in validation_dataset.take(1): # Take one batch from the validation dataset\n",
        "    print(\"\\nValidation Dataset:\")\n",
        "    print(\"Features shape:\", np.array(ft).shape)\n",
        "    print(\"Labels shape:\", np.array(lb).shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0-kuPi-CXzT",
        "outputId": "52b45ae7-2fce-4845-b5df-14a0ed9f4521"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset:\n",
            "Features shape: (1, 164, 20)\n",
            "Labels shape: (1, 164, 9)\n",
            "\n",
            "Validation Dataset:\n",
            "Features shape: (1, 32, 20)\n",
            "Labels shape: (1, 32, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CNN network"
      ],
      "metadata": {
        "id": "yN_4BJEehRJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = tf.keras.Input(shape=(None, 20))  # variable-length sequences\n",
        "\n",
        "x = tf.keras.layers.Conv1D(32, kernel_size=11, padding='same', activation='relu')(input_layer)\n",
        "x = tf.keras.layers.Conv1D(32, kernel_size=7, padding='same', activation='relu')(x)\n",
        "\n",
        "output = tf.keras.layers.Conv1D(9, kernel_size=1, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # use sparse_categorical_crossentropy if labels are integers\n",
        "    metrics=['categorical_accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "kU7s36NxhS6t"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(training_dataset, validation_data=validation_dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "v1lwxBGWjVgf",
        "outputId": "9de675cf-b413-4c7d-bacc-a01c27a3a35e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "   6731/Unknown \u001b[1m31s\u001b[0m 4ms/step - categorical_accuracy: 0.4632 - loss: 1.2146"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - categorical_accuracy: 0.4632 - loss: 1.2145 - val_categorical_accuracy: 0.5073 - val_loss: 1.0829\n",
            "Epoch 2/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - categorical_accuracy: 0.5299 - loss: 1.0573 - val_categorical_accuracy: 0.5466 - val_loss: 1.0331\n",
            "Epoch 3/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - categorical_accuracy: 0.5597 - loss: 1.0065 - val_categorical_accuracy: 0.5613 - val_loss: 1.0101\n",
            "Epoch 4/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6ms/step - categorical_accuracy: 0.5729 - loss: 0.9797 - val_categorical_accuracy: 0.5675 - val_loss: 0.9980\n",
            "Epoch 5/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - categorical_accuracy: 0.5798 - loss: 0.9633 - val_categorical_accuracy: 0.5686 - val_loss: 0.9899\n",
            "Epoch 6/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - categorical_accuracy: 0.5834 - loss: 0.9520 - val_categorical_accuracy: 0.5701 - val_loss: 0.9829\n",
            "Epoch 7/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - categorical_accuracy: 0.5868 - loss: 0.9431 - val_categorical_accuracy: 0.5732 - val_loss: 0.9778\n",
            "Epoch 8/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - categorical_accuracy: 0.5894 - loss: 0.9361 - val_categorical_accuracy: 0.5742 - val_loss: 0.9744\n",
            "Epoch 9/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - categorical_accuracy: 0.5911 - loss: 0.9308 - val_categorical_accuracy: 0.5753 - val_loss: 0.9711\n",
            "Epoch 10/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - categorical_accuracy: 0.5925 - loss: 0.9260 - val_categorical_accuracy: 0.5768 - val_loss: 0.9679\n",
            "Epoch 11/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - categorical_accuracy: 0.5940 - loss: 0.9223 - val_categorical_accuracy: 0.5782 - val_loss: 0.9648\n",
            "Epoch 12/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - categorical_accuracy: 0.5950 - loss: 0.9192 - val_categorical_accuracy: 0.5785 - val_loss: 0.9635\n",
            "Epoch 13/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - categorical_accuracy: 0.5960 - loss: 0.9166 - val_categorical_accuracy: 0.5794 - val_loss: 0.9625\n",
            "Epoch 14/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - categorical_accuracy: 0.5968 - loss: 0.9143 - val_categorical_accuracy: 0.5804 - val_loss: 0.9604\n",
            "Epoch 15/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - categorical_accuracy: 0.5975 - loss: 0.9120 - val_categorical_accuracy: 0.5808 - val_loss: 0.9601\n",
            "Epoch 16/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6ms/step - categorical_accuracy: 0.5981 - loss: 0.9102 - val_categorical_accuracy: 0.5816 - val_loss: 0.9586\n",
            "Epoch 17/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 5ms/step - categorical_accuracy: 0.5988 - loss: 0.9084 - val_categorical_accuracy: 0.5817 - val_loss: 0.9573\n",
            "Epoch 18/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - categorical_accuracy: 0.5992 - loss: 0.9067 - val_categorical_accuracy: 0.5816 - val_loss: 0.9569\n",
            "Epoch 19/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - categorical_accuracy: 0.6002 - loss: 0.9052 - val_categorical_accuracy: 0.5819 - val_loss: 0.9562\n",
            "Epoch 20/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5ms/step - categorical_accuracy: 0.6007 - loss: 0.9038 - val_categorical_accuracy: 0.5825 - val_loss: 0.9558\n",
            "Epoch 21/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - categorical_accuracy: 0.6014 - loss: 0.9027 - val_categorical_accuracy: 0.5829 - val_loss: 0.9545\n",
            "Epoch 22/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - categorical_accuracy: 0.6018 - loss: 0.9015 - val_categorical_accuracy: 0.5834 - val_loss: 0.9533\n",
            "Epoch 23/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - categorical_accuracy: 0.6021 - loss: 0.9005 - val_categorical_accuracy: 0.5836 - val_loss: 0.9525\n",
            "Epoch 24/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - categorical_accuracy: 0.6028 - loss: 0.8995 - val_categorical_accuracy: 0.5838 - val_loss: 0.9519\n",
            "Epoch 25/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - categorical_accuracy: 0.6030 - loss: 0.8986 - val_categorical_accuracy: 0.5843 - val_loss: 0.9518\n",
            "Epoch 26/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 6ms/step - categorical_accuracy: 0.6033 - loss: 0.8978 - val_categorical_accuracy: 0.5844 - val_loss: 0.9520\n",
            "Epoch 27/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 5ms/step - categorical_accuracy: 0.6035 - loss: 0.8971 - val_categorical_accuracy: 0.5846 - val_loss: 0.9507\n",
            "Epoch 28/100\n",
            "\u001b[1m6739/6739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - categorical_accuracy: 0.6040 - loss: 0.8963 - val_categorical_accuracy: 0.5847 - val_loss: 0.9502\n",
            "Epoch 29/100\n",
            "\u001b[1m2824/6739\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6072 - loss: 0.8869"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-335ac907e225>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(hist.history.keys())\n",
        "print(hist.history.values())"
      ],
      "metadata": {
        "id": "RfEqsVPn_iYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot training progress stored in hist\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'hist' is the history object returned by model.fit\n",
        "plt.plot(hist.history['categorical_accuracy'][5:])\n",
        "plt.plot(hist.history['val_categorical_accuracy'][5:])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['loss'][5:])\n",
        "plt.plot(hist.history['val_loss'][5:])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0k_zjKov9mR_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}