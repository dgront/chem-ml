{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Read and parse the training data"
      ],
      "metadata": {
        "id": "SpQH3Un4YYoE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbPd8Ca1Xmuz",
        "outputId": "25a6f69c-7c5b-4f77-9b45-175834ad7cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  pdb_id chain_code                                           sequence  \\\n",
            "0   1a0b          _  TTEENSKSEALLDIPMLEQYLELVGPKLITDGLAVFEKMMPGYVSV...   \n",
            "1   2a00          A  MGHHHHHHHHHHSSGHGGRHNRQASEFIPAQGVDEKTLADAAQLAS...   \n",
            "2   7a0w          A  MKHLHRFFSSDASGGIILIIAAALAMLMANMGATSGWYHDFLETPV...   \n",
            "3   7a0w          B  MKHLHRFFSSDASGGIILIIAAALAMLMANMGATSGWYHDFLETPV...   \n",
            "4   2a06          A  TATYAQALQSVPETQVSQLDNGLRVASEQSSQPTCTVGVWIDAGSR...   \n",
            "\n",
            "                                        region_types  \n",
            "0  UUUUUU1111111111111111111111111111111111111111...  \n",
            "1  UUUUUUUUUUUUUUUUUUUU11111111111111111111111111...  \n",
            "2  UUUUUUUUUUU111HHHHHHHHHHHHHH222222222222222222...  \n",
            "3  UUUUUUUUUU1111HHHHHHHHHHHHHH222222222222222222...  \n",
            "4  2222222222222222222222222222222222222222222222...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace with your actual GitHub repo URL\n",
        "url = \"https://raw.githubusercontent.com/dgront/chem-ml/refs/heads/main/INPUTS/membrane_proteins/pdbtm.dat\"\n",
        "\n",
        "try:\n",
        "  df = pd.read_csv(url, sep='\\t')\n",
        "  print(df.head())  # Display the first few rows of the DataFrame\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = df['sequence'].tolist()\n",
        "region_types = df['region_types'].tolist()\n",
        "print(len(sequences), len(region_types))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBvfrBocYTDU",
        "outputId": "4b192872-ab9c-4155-f672-1f1676917bc0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65705 65705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Encode both inputs and outputs in one-hot encoding\n",
        "write a function that takes 2 arguments:\n",
        "  (1) the list of K characters allowed, say \"12FHU.LBI\"\n",
        "  (2) the string to be encoded\n",
        "The function should return a list of lists or a numpy array NxK with 0 and 1"
      ],
      "metadata": {
        "id": "jNu6YSPyY5CL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6TKJwJK8Y_AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Convert to tensors\n",
        "Make list of \"features\" tensors Nx20, one per each input sequence; also \"labels\" tensors Nx9"
      ],
      "metadata": {
        "id": "6-SSgDsfhc2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Split data into training and validation sets\n",
        "\n",
        "Use existing function as below"
      ],
      "metadata": {
        "id": "YoWqwYYqmYdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# split data into two sets: training and validation\n",
        "\n",
        "features_train, features_val, labels_train, labels_val = train_test_split(features, labels, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "luZ3zYAnmowN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Convert tensors into DataSets"
      ],
      "metadata": {
        "id": "z1Lv1b1h40X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(features_list, labels_list):\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        lambda: zip(features_list, labels_list),\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(None, 20), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(None, 9), dtype=tf.float32)\n",
        "        )\n",
        "    ).batch(1)\n",
        "\n",
        "training_dataset = create_dataset(features_train, labels_train)\n",
        "validation_dataset = create_dataset(features_val, labels_val)"
      ],
      "metadata": {
        "id": "SNOoDA5_46x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Build the model (Neural Network)"
      ],
      "metadata": {
        "id": "1maTCgCWnCMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use \"None\" because of variable-length sequences\n",
        "import tensorflow as tf\n",
        "input_layer = tf.keras.Input(shape=(None, 20))                                                  # First = input layer\n",
        "\n",
        "x2 = tf.keras.layers.Conv1D(64, kernel_size=3, padding='same', activation='relu')(input_layer)  # Second layer = first hidden layer\n",
        "x3 = tf.keras.layers.Conv1D(64, kernel_size=3, padding='same', activation='relu')(x2)           # Third layer = second hidden layer\n",
        "\n",
        "output = tf.keras.layers.Conv1D(9, kernel_size=1, activation='softmax')(x3)                     # Fourth = output layer\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # use sparse_categorical_crossentropy if labels are integers\n",
        "    metrics=['categorical_accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "kuOKPs4DnOQW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Train the model"
      ],
      "metadata": {
        "id": "g_ZMavm7nIYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(training_dataset, validation_data=validation_dataset, epochs=100)"
      ],
      "metadata": {
        "id": "dx4UShqMpZ5u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}